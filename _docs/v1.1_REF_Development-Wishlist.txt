================================================================================
HAVONA ANVIL SUITE — DEVELOPMENT WISHLIST
================================================================================
Project:        AWSNBLM (Havona Anvil Suite)
Version:        v1.1
File Class:     REF
Created:        2026-02-10
Updated:        2026-02-13
Session:        027 (merged S026 addenda + new items)

PURPOSE:
Consolidated repository of all development ideas, feature requests, and
improvement items for the HA Suite. This is the single source of truth
for "what do we want to build." Items are tracked from idea through
implementation, with status and priority.

MAINTENANCE:
When new ideas surface in any session, add them here via Chronicler.
When items are completed, update status and note the session. Sync to
HA Suite NLM notebook when updated. This file lives in _docs/ and
follows the standard NLM sync protocol.

================================================================================
STATUS KEY
================================================================================

  IDEA        — Identified, not yet scoped or committed
  SCOPED      — Architecture/approach defined, ready to build
  IN PROGRESS — Active development
  COMPLETE    — Built and operational
  DEFERRED    — Intentionally delayed (reason noted)
  SUPERSEDED  — Replaced by another approach

================================================================================
PRIORITY KEY
================================================================================

  P1 — Critical path (blocks production work)
  P2 — High value (significant efficiency gain)
  P3 — Medium value (quality of life improvement)
  P4 — Low priority (nice-to-have, future consideration)

================================================================================
SECTION 1: CONDUCTOR — NLM AUTOMATION ORCHESTRATION SERVICE
================================================================================

Conductor is a planned independent MCP service on EC2 that automates
multi-step NLM workflows. It calls Majeston internally (Path A) or the
NLM API directly (Path B, future). Claude triggers workflows and reads
results; the script handles the iterative heavy lifting.

Architecture decision: D-038 (S024) — build as independent service,
do not modify Majeston/jacob-bd codebase.

Analogy: Claude is front-of-house (takes the order, customizes it).
Conductor is the kitchen (executes the recipe, plates the result).

--------------------------------------------------------------------------------
W-100: CONDUCTOR — Foundation Service
--------------------------------------------------------------------------------
Priority:    P2
Status:      SCOPED (S023)
Depends on:  EC2 infrastructure (operational), Majeston (operational)

Description:
Stand up the Conductor as a Python MCP server on EC2, alongside Majeston.
Initial capability: accept tool calls from Claude, execute NLM queries
via Majeston's localhost API, return results.

Architecture:
- Python FastMCP service on dedicated port
- Caddy route: /conductor/* → localhost:{port}
- Calls Majeston at localhost:8100 (through socat for traffic capture)
  OR localhost:8000 (through socat, captured by SeraphRecorder)
- Results written to files (repo via Chronicler or local + push)
- systemd managed, auto-restart

Build estimate: 1-2 sessions

--------------------------------------------------------------------------------
W-101: NLM Registry Auto-Refresh
--------------------------------------------------------------------------------
Priority:    P2
Status:      SCOPED (S023)
Depends on:  W-100 (Conductor foundation)

Description:
Automated tool that rebuilds the complete NLM notebook and source ID
registry. Replaces the static Notebook Directory (v1.0_REF) with a
living, auto-updated registry.

Workflow:
1. Call notebook_list → get all notebook IDs and titles
2. For each notebook, call notebook_get → get all source IDs and titles
3. Write structured JSON registry to known location
4. Optionally push to GitHub repo via Chronicler

Modes:
- On-demand: Claude triggers via MCP tool call
- Scheduled: cron job (daily or weekly)

Output: nlm-registry.json (structured, queryable)
  - All notebooks with IDs, titles, source counts, modified dates
  - All sources within each notebook with IDs and titles
  - Timestamp of last refresh

Build estimate: 1 session (once W-100 foundation exists)

--------------------------------------------------------------------------------
W-102: Query Data Reporter
--------------------------------------------------------------------------------
Priority:    P2
Status:      SCOPED (S023)
Depends on:  SeraphRecorder JSONL archive (operational)

Description:
Reporting tool that parses SeraphRecorder JSONL logs and generates
structured reports on all Majeston queries. Solves the transcript
invisibility problem — queries executed in MCP are invisible in chat
transcripts; this tool recovers them from traffic logs.

Capabilities:
- List all queries from a specific session
- List all queries targeting a specific notebook
- Full query text recovery
- Query frequency by pass type
- Response size/quality metrics
- Auto-populate query_text field in query-manifest.json

Input: JSONL files at /home/ubuntu/mcp-logs/raw/
Output: Structured reports (text or JSON) to repo or local file

Note: Could initially be a standalone script (no MCP needed). Promote
to Conductor tool if frequently triggered by Claude.

Build estimate: 1-2 sessions

--------------------------------------------------------------------------------
W-103: Theme Saturation Automation
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA
Depends on:  W-100 (Conductor), validated theme extraction workflow

Description:
Automated iterative theme extraction. Conductor queries NLM repeatedly,
each time excluding previously identified themes, until saturation is
detected (NLM returns no new themes or response drops below threshold).

Saturation detection approaches:
- Response length drops below threshold
- NLM explicitly states no additional themes
- Semantic similarity to prior responses exceeds threshold
- Fixed iteration cap with diminishing returns assessment

Output: Consolidated theme list with iteration metadata

Prerequisite: Theme extraction workflow must be standardized through
CLGYSING/NLMINTA testing before automation can be built.

Build estimate: 1-2 sessions (once workflow is standardized)

--------------------------------------------------------------------------------
W-104: Batch Extraction Orchestrator
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA
Depends on:  W-100 (Conductor), validated extraction query templates

Description:
Execute a series of predefined extraction queries against a notebook.
Claude submits a "work order" specifying notebook, source scope, pass
types, and any custom parameters. Conductor executes the full battery
and writes all results to organized files.

Potential recipe examples:
- "Full SP evaluation": PE → TM → CE → VX → TS (5-pass sequence)
- "Deep concept extraction": iterative CE with exclusion lists
- "Vocabulary sweep": VX with progressive narrowing

Prerequisite: Extraction workflows must be standardized and pass-type
query templates must be validated.

Build estimate: 2-3 sessions (once recipes are defined)

--------------------------------------------------------------------------------
W-105: Conductor Path B — Direct NLM API Access
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA
Depends on:  W-100 operational, jacob-bd source code analysis

Description:
Evolve Conductor from calling Majeston internally (Path A) to calling
the NLM API directly (Path B). This provides independence from Majeston
and enables parallel query execution.

Prerequisite: Analyze jacob-bd source code to understand NLM auth flow,
API endpoints, session management. Extract patterns for independent
implementation.

Build estimate: 3-5 sessions (significant reverse engineering)

================================================================================
SECTION 2: SERAPHRECORDER PIPELINE
================================================================================

--------------------------------------------------------------------------------
W-005: Auto-Extraction Automation
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA
Depends on:  Pipeline stability

Description:
Replace manual extraction trigger with cron job or file watcher that
runs extract.py and push-to-github.sh automatically after traffic stops.

Currently: daily-rotate.sh runs at midnight UTC.
Enhancement: detect traffic cessation and extract sooner, or add
mid-day extraction pass.

--------------------------------------------------------------------------------
W-013: Extract.py Date Fallback
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA

Description:
Enhance extraction script date fallback logic for edge cases.

--------------------------------------------------------------------------------
W-020: JSONL Archival to GitHub (D-019)
--------------------------------------------------------------------------------
Priority:    P3
Status:      DEFERRED (since S017)

Description:
Modify push-to-github.sh to push raw JSONL logs to /raw/YYYY-MM/ on
GitHub for permanent archival. Currently JSONL stays on EC2 only.

--------------------------------------------------------------------------------
W-021: Historical Reprocessing Validation
--------------------------------------------------------------------------------
Priority:    P4
Status:      DEFERRED (since S019)

Description:
Validate that pipeline can cleanly reprocess historical traffic logs.

--------------------------------------------------------------------------------
W-022: Remove Debug Flags
--------------------------------------------------------------------------------
Priority:    P4
Status:      DEFERRED (since S014)

Description:
Remove --verbose debug flags from extract.py production deployment.

--------------------------------------------------------------------------------
W-023: Branch-Aware Extraction Routing
--------------------------------------------------------------------------------
Priority:    P2
Status:      SCOPED (S026, from NLMINTA S018 Insight 3)

Description:
Enable automatic routing of extraction outputs to branch-specific folders
in the GitHub repo. Currently, all extractions from all branches/projects
land in a single _untagged/ folder with no way to distinguish origin
without manual inspection.

Problem context: 5+ active branches (AWSNBLM, NLMINTA, CLGYSING, etc.)
plus external testers all generate Majeston queries. Output volume now
~400+ files with no branch-level sorting.

Three implementation tiers:

Tier 1 (Process discipline — implementable now):
  Extend SERAPH signal format to include BRANCH field:
  [SERAPH: BRANCH=AWSNBLM, SESSION=026, PROJECT=clgysing, PASS=VX]
  extract.py already parses SERAPH tags. Add BRANCH to routing logic.
  Route to: _untagged/{BRANCH}/ or {BRANCH}/{PROJECT}/{PASS}/
  Discipline: Session bootstraps require SERAPH tag on all queries.
  Build estimate: <1 session (extract.py modification only)

Tier 2 (Session context registration — medium effort):
  New Chronicler tool: register_session(branch, session_number)
  Writes context file that extract.py reads for time-window matching.
  All extractions during active session inherit branch tag.
  Risk: Time-window overlap if multiple sessions run simultaneously.
  Build estimate: 1 session

Tier 3 (Proxy-level injection — highest effort, cleanest):
  Modify socat wrapper or build thin proxy that intercepts all Majeston
  calls and injects branch metadata into request before forwarding.
  Every tool call automatically carries branch tag.
  Build estimate: 2-3 sessions

Recommended path: Tier 1 first (zero infrastructure changes needed).
SERAPH Branch Tagging Directive v1.0 created in S026 as Tier 1 implementation.

Relates to: NLMINTA S018 Insight 3, W-001 (File Routing), W-100 (Conductor)

================================================================================
SECTION 3: CHRONICLER ENHANCEMENTS
================================================================================

--------------------------------------------------------------------------------
W-003: Notebook Source Addition from GitHub
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA

Description:
Close the loop between Chronicler and Majeston: read organized files
from GitHub repo and programmatically add them as NLM notebook sources.
Currently limited by file upload path (text summary workaround used).

--------------------------------------------------------------------------------
W-004: Extraction Tagging System
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA
Depends on:  W-002 (COMPLETE)

Description:
Claude reads extraction file headers, updates metadata fields, renames
files per Indexer conventions. Partially addressed by Indexer protocol
but could benefit from tooling.

--------------------------------------------------------------------------------
W-030: Batch Operations
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA

Description:
batch_move or batch_organize tool for multiple file operations in a
single commit. Useful for large-scale file reorganization.

--------------------------------------------------------------------------------
W-031: Search Functionality
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA

Description:
search_files tool using GitHub code search API to find specific
concepts across the repository without reading every file.

--------------------------------------------------------------------------------
W-032: Metadata Index
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA

Description:
Build metadata-index.json for quick lookups without reading every file.
May be partially addressed by query-manifest.json.

--------------------------------------------------------------------------------
W-049: Caliper Subdirectory Recursion
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S026, from NLMINTA S016 brief)

Description:
Add optional recursive parameter to Caliper's analyze_github_folder tool
to scan all subdirectories and produce a unified inventory report. Currently
requires separate calls per directory.

Implementation: Add recursive flag that walks subdirectories, aggregating
file metrics into a single structured response. Include directory path
in per-file output for disambiguation.

Build estimate: <1 session

================================================================================
SECTION 4: INFRASTRUCTURE & MAINTENANCE
================================================================================

--------------------------------------------------------------------------------
W-040: GitHub PAT Rotation
--------------------------------------------------------------------------------
Priority:    P3
Status:      DEFERRED (since S011)

Description:
Rotate Personal Access Token used by Caliper, Chronicler, File Browser,
and push-to-github.sh. Deferred to avoid service disruption — needs
coordinated update across all tools.

--------------------------------------------------------------------------------
W-041: Health Check Update
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA

Description:
Update health-check.sh to include Caliper, Chronicler, File Browser,
Transcript Receiver, and Conductor (when built) in diagnostic checks.

--------------------------------------------------------------------------------
W-042: jacob-bd Source Code Backup
--------------------------------------------------------------------------------
Priority:    P2
Status:      PARTIALLY ADDRESSED (S024 — backup created pre-upgrade)

Description:
Archive the installed jacob-bd (notebooklm-mcp-cli) source code as
insurance against upstream project abandonment. Copy from uv install
directory to a backup location (local or repo).

S024 created jacob-bd-backup-v0.2.15.tar.gz before upgrading to v0.2.18.
Ongoing: should backup after each upgrade.

--------------------------------------------------------------------------------
W-043: jacob-bd Update Automation
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S023)

Description:
Standardize jacob-bd upgrade process: backup → upgrade → restart →
verify → refresh auth if needed. Could be scripted.

--------------------------------------------------------------------------------
W-044: Shell MCP Connector
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA (S020)

Description:
Dedicated MCP tool exposing EC2 shell access. Would allow Claude to
run commands and manage filesystem without SSH/Termius. Significant
security considerations.

--------------------------------------------------------------------------------
W-045: EC2 Cost Review
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA (S022)

Description:
Evaluate whether t3.small is still necessary or if t3.micro could
work again after Docker removal and service optimization. Currently
~$15/month vs ~$8/month.

--------------------------------------------------------------------------------
W-046: Tailscale Stability Monitoring
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S022)

Description:
Monitor Tailscale VPN for recurring drops. Dropped in S022, was
restarted. If unstable, evaluate alternatives or add auto-restart.

--------------------------------------------------------------------------------
W-047: Mobile Transcript Capture
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S025, formalized S026)

Description:
A solution (bookmarklet, browser extension alternative, or service) to
capture Claude conversation transcripts on mobile devices where Chrome
extensions like Claude Exporter do not work. The Transcript Receiver
(port 8096) was built in S025 as a paste-based workaround, but mobile
copy-paste of full transcripts proved impractical due to UI limitations.

Approaches to evaluate:
- Bookmarklet that extracts conversation DOM and POSTs to receiver
- Mobile browser automation (Shortcuts on iOS)
- Claude API transcript export (if/when available)
- Alternative: accept mobile sessions as lower-fidelity and prioritize
  desktop for transcript-critical work

Stretch: Automate routing of captured transcripts into GitHub repo and
NLM notebooks (originally tracked as separate auto-archive concept,
folded here as end-to-end pipeline).

--------------------------------------------------------------------------------
W-048: EC2 Configuration Backup
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S025, formalized S026)

Description:
Periodic snapshot of the /home/ubuntu/ directory structure (scripts,
configs, .env files, service definitions) to GitHub or Google Drive.
Currently, EC2 configuration is not backed up — if the instance is
terminated, all custom scripts and configurations would need to be
rebuilt from session transcripts.

Approach options:
- Chronicler-based: tar + push key directories to repo
- rsync to Google Drive (via rclone)
- Cron job: weekly snapshot to _backups/ in repo
- Selective: only backup changed files (git diff approach)

Excludes: Large binary files, node_modules, auth tokens (security)

================================================================================
SECTION 5: INDEXER ENHANCEMENTS
================================================================================

--------------------------------------------------------------------------------
W-050: Indexer Alpha Production Testing
--------------------------------------------------------------------------------
Priority:    P2
Status:      IDEA

Description:
First production use of Indexer conventions with real CLGYSING
extraction work. Validates or refines v0.2 spec.

--------------------------------------------------------------------------------
W-051: Manifest Format Evaluation
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA

Description:
Evaluate JSON manifest format at ~100 entries. Consider alternatives
(SQLite, flat log) if JSON becomes unwieldy.

--------------------------------------------------------------------------------
W-052: Full Degree Chain Test
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA

Description:
Execute complete D1→D2→D3→DM consolidation chain to validate degree
classification system in practice.

--------------------------------------------------------------------------------
W-001: File Routing Logic
--------------------------------------------------------------------------------
Priority:    P3
Status:      PARTIALLY ADDRESSED
Note:        Indexer protocol + Chronicler move_file addresses this.
             Full automation deferred to Conductor development.

================================================================================
SECTION 6: AIPM & WORKFLOW
================================================================================

--------------------------------------------------------------------------------
W-006: AIPM Repo Integration
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S018)

Description:
Use Chronicler to write session artifacts (logs, bootstraps, decision
logs) directly to GitHub. Reduces manual file management.

================================================================================
SECTION 7: FILE BROWSER ENHANCEMENTS
================================================================================

--------------------------------------------------------------------------------
W-060: Custom Batch Select
--------------------------------------------------------------------------------
Priority:    P4
Status:      IDEA (S023)

Description:
Add checkbox selection for custom batch downloads (select specific
files across directories, download as ZIP). Folder ZIP covers the
main use case; this is a convenience enhancement.

--------------------------------------------------------------------------------
W-061: NLM-to-Repo Ingestion Tool
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S026, from NLMINTA S016 brief)

Description:
Cross-service orchestration tool combining Majeston + Chronicler + Caliper
to ingest NotebookLM source content to a repo staging folder with optional
analysis. Claude triggers a single tool call; the pipeline reads NLM
source content, writes it to the repo, and optionally runs Caliper
analysis.

Workflow:
1. Majeston:source_get_content → retrieve raw text
2. Chronicler:write_file → save to repo staging folder
3. (Optional) Caliper:analyze_github_folder → generate metrics

Could be a Conductor workflow (W-100 dependent) or a manual Claude
multi-tool sequence documented as a standard operating procedure.

Build estimate: 1 session (as Conductor workflow) or 0 sessions (as SOP)

================================================================================
SECTION 8: DOCUMENTATION & VISUALIZATION
================================================================================

--------------------------------------------------------------------------------
W-062: Comprehensive Diagram Suite
--------------------------------------------------------------------------------
Priority:    P3
Status:      IDEA (S027)

Description:
Create a complete set of Mermaid diagrams covering all HA Suite flows
and architecture. Two versions of each diagram:

  Technical version: Full detail for developers and maintainers.
    Includes ports, service names, file paths, protocol details.

  Annotated version: Plain-English explanation bubbles for colleagues
    and new users who want to understand the system without deep
    technical background. Suitable for onboarding.

Diagrams to create:
- Request flow (Claude → Caddy → services)
- SeraphRecorder pipeline (capture → extract → push → organize)
- Authentication flows (Majeston refresh, PAT management)
- NLM sync protocol (doc update → NLM notebook swap → manifest)
- File organization flow (extraction → Indexer → degree progression)
- Conductor architecture (when built — W-100)
- Mobile operations overview
- Pipeline trigger paths (existing — expand with annotations)

Existing diagrams (S026):
- core-extraction-pipeline.mermaid (technical)
- pipeline-trigger-paths.mermaid (technical)

Build estimate: 2-3 sessions for full suite

================================================================================
SECTION 9: FUTURE TOOL CONCEPTS (LIBFORGE ECOSYSTEM)
================================================================================

These are conceptual tools from the LibForge vision. They follow the
Urantia/Craft naming convention and represent long-term possibilities.

W-070: Flux        — Data cleaning/preprocessing (strip fluff)
W-071: Anvil       — Prose generation and drafting engine
W-072: Crucible    — Synthesis tool (melt raw materials into unified output)
W-073: Drawplate   — Compression tool (progressive refinement)
W-074: Censors     — Fact-checking and validation (after Urantia Universal Censors)
W-075: Bellows     — Performance booster / parallelization for batch ops

Status: All IDEA. These depend on LibForge methodology stabilization and
significant Conductor maturation. Long-term horizon.

================================================================================
COMPLETED ITEMS
================================================================================

W-002: GitHub Repo Interaction Tool (Chronicler)
  Status:    COMPLETE (S017)
  Notes:     Deployed as Chronicler MCP tool with 10 tools

File Browser Auth Fix
  Status:    COMPLETE (S023, D-035)
  Notes:     Bcrypt hash format mismatch resolved

Concept Counter Reset
  Status:    COMPLETE (S022)
  Notes:     Reset to clean {} for production

Chronicler flush_pipeline Discovery Fix
  Status:    COMPLETE (S026)
  Notes:     Function reordering before mcp.run() entry point

SERAPH Branch Tagging Directive
  Status:    COMPLETE (S026)
  Notes:     v1.0 directive created, Tier 1 of W-023

================================================================================
DOCUMENT HISTORY
================================================================================

Version  Date        Session  Description
-------  ----------  -------  ------------------------------------------------
v1.0     2026-02-10  S023     Initial consolidated wishlist. Merged items from
                              SeraphRecorder Wishlist v1.0, CHANGELOG pending
                              items, session transcripts (W-001 through W-009),
                              and new S023 items (Conductor vision, registry,
                              query reporter, jacob-bd backup). Renumbered
                              into organized sections (W-1xx Conductor, W-0xx
                              legacy, W-0[3-6]x by component).
v1.1     2026-02-13  S027     Merged S026 addenda (W-023, W-047, W-048, W-049,
                              W-061). Added W-062 (Comprehensive Diagram Suite).
                              New Section 8 (Documentation & Visualization).
                              Updated completed items. Reformatted Section 2
                              for W-023 integration.

================================================================================
END OF DEVELOPMENT WISHLIST
================================================================================