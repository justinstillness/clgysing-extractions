================================================================================
EXTRACTION: 2026-02-08_035108_notebook-query
================================================================================
Source Package:  N/A
Pass Type:       N/A (N/A)
Pass Number:     N/A
Theme/Focus:     Untagged
Query:           List every finding (F01 through the highest number) documented across all sessions. For each finding, provide the finding number, a brief title or description, and which session it was documented in. Present as a complete numbered list.
Timestamp:       2026-02-08T03:51:08.000450+00:00
Notebook ID:     b8fd3d1c-db62-40e6-bddf-6d8474a3733d
Source IDs:      all
Conversation ID: 39ca6227-f52c-4c52-b958-eba0f87056f3
Chat Configure:  default
Response Chars:  10463
Duration:        56999ms
================================================================================

Here is the complete list of findings (F01...F54) documented across the project sessions, based on the Phase 2 Findings sequence.\
\
1.  **F01: notebook_describe ... Insufficient for Material Inventory** (Session 007)\
    Found to return only a one-paragraph summary, which is too compressed for detailed inventory generation.\
2.  **F02: source_describe ... Highly Effective for Per-Source Cataloging** (Session 007)\
    Returns substantive summaries with keywords, suitable for content overview and priority assessment.\
3.  **F03: notebook_query ... Rich Operational Intelligence** (Session 007)\
    Can generate structured metadata (counts, formats, priorities) when queried specifically about operational details.\
4.  **F04: Metadata-as-Source Pattern Discovered** (Session 007)\
    Uploading a metadata/inventory document as a source allows NotebookLM to answer questions it otherwise couldn't (e.g., word counts).\
5.  **F05: studio_create (data_table) ... Automated Metadata Generation** (Session 007)\
    Excellent for rapid generation of topic, domain, and status tables, though with some accuracy limitations.\
6.  **F06: Data Table Quality Dramatically Improves with Inventory Doc** (Session 007)\
    Presence of an inventory document allows the data table tool to produce full filenames, DDS codes, and status columns.\
7.  **F07: Word Count Accuracy is Unreliable in Data Tables** (Session 007)\
    NotebookLM estimates rather than precisely counts words; values differed from known validations.\
8.  **F08: Filesystem Boundary ... NLM Outputs Stay on EC2** (Session 007)\
    Downloaded artifacts land on the server filesystem, not the Claude environment, requiring specific export pathways.\
9.  **F09: Export Pathway for Claude-Readable Output** (Session 007)\
    Reports exported to Google Docs are readable by Claude; data tables exported to Sheets are not directly readable.\
10. **F10: notebook_query with source_ids ... Excellent for Voice Analysis** (Session 007)\
    Filtering by source allows targeted analysis of \"posted content\" for voice and style without contamination.\
11. **F11: notebook_query ... Excellent for Terminology Extraction** (Session 007)\
    A single query can produce a near-complete draft of a terminology guide with definitions and quotes.\
12. **F12: source_ids Filtering ... Key Operational Capability** (Session 007)\
    Essential for isolating specific subsets of the corpus (e.g., just published articles) for analysis.\
13. **F13: Single Queries Produce Draft-Quality Artifacts** (Session 007)\
    Outputs are often structured and categorized enough to serve as first drafts of deliverables (guides, maps).\
14. **F14: Conversation Threading Enables Iterative Deepening** (Session 007)\
    Using `conversation_id` allows follow-up queries to build on prior context within a session.\
15. **F15: notebook_query ... Excellent for Concept Extraction** (Session 007)\
    Can extract structured concept packets (title, quote, category, content) matching manual quality.\
16. **F16: Stale Source ID Hazard** (Session 007)\
    Source IDs can change when notebooks are modified; IDs must be verified at the start of sessions.\
17. **F17: NLM Output Format Aligns with Concept Packet Template** (Session 007)\
    Natural output structure mirrors the project's requirements (Title, Source, Category, Quote, etc.).\
18. **F18: NLM Extraction Scales to Large Sources** (Session 007)\
    Extraction works on large documents (60k+ words) via targeted, segmented queries.\
19. **F19: Attribution Correction ... Integration vs. Source Content** (Session 007)\
    NLM extracts integration notes present in the source rather than generating new integrations itself.\
20. **F20: Thematic Segmentation Superior to Sequential Segmentation** (Session 007)\
    Extracting by theme/topic is more effective than chunking by word count due to NLM's semantic nature.\
21. **F21: Thematic Extraction Produces Comparable Yields to Dedicated AI Sessions** (Session 007)\
    Thematic extraction yields are comparable to individual AI extraction sessions (e.g., ~74 raw packets from a small source).\
22. **F22: Theme Mapping Spontaneous Extraction** (Session 008)\
    Theme mapping queries on small sources may return full concept packets instead of just a list of themes.\
23. **F23: TX Passes Produce Significant New Concepts Beyond TM** (Session 008)\
    Dedicated thematic extraction (TX) passes find concepts missed during the initial theme mapping (TM).\
24. **F24: Parasitic Systems and Cultology Framework Richest Themes** (Session 008)\
    Theme yield correlates directly with the density of that topic within the source text.\
25. **F25: Gap Detection Finds Only Meta/Operational Content** (Session 008)\
    After thorough thematic extraction, gap detection primarily finds biographical or logistical details.\
26. **F26: Raw Packet Yield ... 134 Total, ~45-60 Unique Estimated** (Session 008)\
    High redundancy (2-3x) across themes ensures comprehensive coverage and rich cross-referencing.\
27. **F27: Note Save Method ... Content Passes Through Wire Twice** (Session 008)\
    Saving to notes requires receiving the text and then sending it back to create the note, doubling token cost.\
28. **F28: Note Content Truncation Risk** (Session 008)\
    Saving condensed summaries risks data loss if the chat context is cleared; full content must be persisted.\
29. **F29: Note Update Tool Works for Content Replacement** (Session 008)\
    The update tool can successfully replace truncated notes with full content if th< 2026/02/08 03:52:05.000280498  length=4922 from=16885 to=21806
e data is available.\
30. **F30: Query Provenance Tracking ... Essential Metadata** (Session 008)\
    Recording the exact query text in the saved note is critical for methodology tracking.\
31. **F31: Conversation_id Threading Maintained Across All Passes** (Session 008)\
    Threading works across long sequences (13+ queries) without apparent degradation.\
32. **F32: Default chat_configure Produced Rich Results** (Session 008)\
    Default settings yielded high-quality, structured outputs even without a custom system prompt.\
33. **F33: Save Protocol Naming Convention ... Validated** (Session 008)\
    The file naming convention (SP[##]-[PASS][SEQ]-[Theme]_[Project]) works effectively in practice.\
34. **F34: chat_configure Custom Prompt ... Nudges Quality, Doesn't Transform** (Session 009)\
    Custom prompts influence formatting (e.g., adding IDs) but don't radically change extraction substance.\
35. **F35: response_length=\"longer\" Controls Depth, Not Breadth** (Session 009)\
    Setting response length to \"longer\" results in deeper individual entries, not a higher number of entries.\
36. **F36: Different Configs Surface Unique Concepts** (Session 009)\
    Running both default and custom configurations reveals different concepts; neither is a strict superset.\
37. **F37: Custom Prompt Partially Influences Behavior** (Session 009)\
    Soft guidance (like \"flag contradictions\") is often ignored, while formatting requests are adopted.\
38. **F38: Template-as-Source Does Not Passively Influence Extraction** (Session 009)\
    Uploading a template/legend as a source does not cause NLM to automatically adopt it for formatting.\
39. **F39: Template-as-Source Useful for Query-Directed Classification** (Session 009)\
    NLM *will* use an uploaded template if explicitly directed to classify content using that specific source.\
40. **F40: NLM Operates With Two Knowledge Layers** (Session 009)\
    NLM bridges its general training (Layer 2) with source content (Layer 1) to handle non-standard classification.\
41. **F41: VX Pass Produces Qualitatively Distinct Output From TX** (Session 010)\
    Vocabulary Extraction (VX) creates term-centric glossary entries distinct from Concept Extraction (TX).\
42. **F42: TS Pass Extracts Argumentative Architecture** (Session 010)\
    Thesis String (TS) extraction successfully identifies declarative claims, evidence, and logical relationships.\
43. **F43: EV Pass Produces Substantive Critical Analysis** (Session 010)\
    Evaluation (EV) passes can identify cross-source contradictions, logical gaps, and factual issues.\
44. **F44: Combined Passes Sacrifice Depth for Breadth** (Session 010)\
    Asking for Concepts, Vocabulary, and Theses in one query results in lower yield and depth for each.\
45. **F45: Pass Separation Principle ... Methodology Recommendation** (Session 010)\
    Extraction should be segmented by pass type (TX, VX, TS, EV) to maximize yield and quality.\
46. **F46: Degree-One / Degree-Two Extraction Pipeline Model** (Session 010)\
    Pipeline defined: Degree-One extracts raw datasets; Degree-Two harmonizes them into a master library.\
47. **F47: NLM Self-Organizes Output Into Taxonomic Groups** (Session 010)\
    NLM may spontaneously group terms taxonomically, though this may not match the project's specific domain system.\
48. **F48: Connector Transparency Gap Identified and Resolved** (Session 010)\
    Protocol established to document invisible connector tool calls inline for transcript completeness.\
49. **F49: Proprietary Vocabulary Glossary Does Not Measurably Improve NLM Extraction** (Session 011)\
    Uploading a glossary note is redundant if the source material already contains sufficient definitions.\
50. **F50: Thesis-as-Lens Produces Qualitatively Different Extraction** (Session 011)\
    Using a thesis statement as a \"lens\" filters out peripheral concepts and deepens the treatment of relevant ones.\
51. **F51: Thesis-Lens Extraction May Enable Direct ArgBlock Construction** (Session 011)\
    Hypothesis: Thesis-guided extraction might bypass general extraction for targeted drafting work (Phase 4).\
52. **F52: NLM Output Envelope ... Adding Context Redistributes Rather Than Expands Total Output** (Session 011)\
    Adding context (lens/glossary) yields fewer, richer items; it does not increase the total volume of output.\
53. **F53: NLM Thesis Generation Quality Is High at Degree-One Depth** (Session 011)\
    NLM can generate coherent single-layer thesis trees (Master + Sub-theses) from extraction products.\
54. **F54: Concept-Centric Lexicon Development ... Pipeline Limitation Identified** (Session 011)\
    Source terminology fluidity requires a \"concept-centric\" approach: extract provisional terms (VX), then refine concepts to stabilize the lexicon.

================================================================================
END OF EXTRACTION
================================================================================
