================================================================================
EXTRACTION: 2026-02-09_011341_notebook-query
================================================================================
Branch:          N/A
Source Package:  N/A
Pass Type:       N/A (N/A)
Pass Number:     N/A
Theme/Focus:     Untagged
Routing:         Tier 3 (Untagged)
Query:           extract.py current code version 4 parsing logic file naming metadata header structure
Timestamp:       2026-02-09T01:13:41.000912+00:00
Notebook ID:     78ccac4a-4c28-4902-b721-0f77e25e1d59
Source IDs:      all
Conversation ID: 6d052077-27c6-4b8f-a746-78dac209d75f
Chat Configure:  default
Response Chars:  3777
Duration:        33999ms
================================================================================

Based on the sources, here is the detail regarding the current `extract.py` code (Version 4), its parsing logic, file naming conventions, and metadata header structure.

### 1. Current Code Version: `extract.py` v4
The current version of the extraction script is **v4**, finalized during **Session 014** and confirmed in the file manifest during Session 016 [1].

*   **Size:** Approximately 27KB [1].
*   **Key Fix (v4):** The final modification defining this version addressed a JSON parsing error caused by `socat`'s double-escaping of quote characters inside the SSE data stream. The fix involved normalizing `"` to `"` before attempting `json.loads` [2], [3].

### 2. Parsing Logic
The script parses raw traffic logs generated by `socat` (which proxies traffic between Caddy and the NotebookLM MCP). The logic was iteratively refined to handle the complexities of the MCP "Streamable HTTP" transport protocol [4], [2].

*   **Input Format:** Reads `socat -v` logs containing directional blocks (`>` for requests, `<` for responses) with HTTP headers, chunked transfer encoding (hex sizes), and SSE (Server-Sent Events) data [5], [6].
*   **Single-Pass Sequential Matching:** It walks through the log blocks sequentially. It extracts JSON request bodies (sometimes found in the `pre_data` of the subsequent block due to logging artifacts) and queues them as "pending" [7].
*   **FIFO ID Correlation:** It matches pending requests to responses based on the JSON-RPC `id`. Because the MCP protocol resets IDs (e.g., `id:1`) for every new session, the parser uses a "First-In-First-Out" approach to ensure a request matches the *next* unclaimed response with the same ID, rather than a response from a different session [4].
*   **Protocol Filtering:** It actively filters out protocol-level responses (like `initialize` and `tools/list`) to prevent them from consuming the matches meant for actual tool calls like `notebook_query` [7].
*   **Output Streams:**
    *   **Stream 1 (Raw):** Writes structured JSONL files (one entry per tool call) to `/home/ubuntu/mcp-logs/raw/` [8].
    *   **Stream 2 (Extracted):** Filters specifically for `notebook_query` results, extracts the answer text, and writes clean text files to `/home/ubuntu/mcp-logs/extracted/_untagged/` [9].

### 3. File Naming Convention
The script names extracted text files based on whether it detects a "Signal String" (metadata tags) in the query text.

*   **Default (Untagged):** If no signal string is found, it uses a timestamp-based format to ensure uniqueness:
    *   Format: `YYYY-MM-DD_HHMMSS_notebook-query.txt`
    *   Example: `2026-02-06_212516_notebook-query.txt` [10], [11].
*   **Tagged (Signal String):** If the query includes a block like `[SERAPH: PROJECT=clgysing, SP=03...]`, the parser uses these fields to construct a semantic filename:
    *   Format: `YYYY-MM-DD_HHMMSS_{PROJECT}_{SP}_{PASS}-{NUM}_notebook-query.txt` [11].

### 4. Metadata Header Structure
Every extracted text file begins with a structured metadata header block that preserves the provenance of the data.

**Current Structure (as verified in Session 014):**
```text
### EXTRACTION: 2026-02-07_023233_notebook-query
### Source Package:  N/A
Pass Type:       N/A (N/A)
Pass Number:     N/A
Theme/Focus:     Untagged
Query:           [Full text of the query sent to NotebookLM]
Timestamp:       2026-02-07T02:32:33.000130+00:00
Notebook ID:     [UUID of the notebook queried]
Source IDs:      all
Conversation ID: [UUID of the conversation thread]
Chat Configure:  default
Response Chars:  8323
Duration:        37000ms
```
*Note: The fields "Source Package," "Pass Type," etc., currently show "N/A" or "Untagged" because the Signal String format has not yet been implemented in the extraction queries [12], [13].*

================================================================================
END OF EXTRACTION
================================================================================
